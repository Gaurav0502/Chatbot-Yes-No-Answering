{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313a2451",
   "metadata": {},
   "source": [
    "# Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0f0573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import spacy\n",
    "import re\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2138c57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "     -------------------------------------- 79.7/79.7 kB 221.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.19.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.6.5)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.5.18.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120735 sha256=f61beb28f0900e4ed36e348db670a579326c3b2907b52ff1135e3209ac251875Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Stored in directory: c:\\users\\mitug\\appdata\\local\\pip\\cache\\wheels\\2b\\11\\3b\\32a18fb9f2253b25d3d1a06f0a84e2d516e7efa19c8c71a283\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: torchvision, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.0 torchvision-0.12.0\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f0914",
   "metadata": {},
   "source": [
    "# Question Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6784fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a train connection between Delhi and Mumbai?\n"
     ]
    }
   ],
   "source": [
    "qs = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd836dd",
   "metadata": {},
   "source": [
    "# Intent Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf16c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"..\\data\\intent_classification_data.json\")\n",
    "data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b32aa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainCheck': ['Is X the train number of Y?', 'Does X have train number Y?'],\n",
       " 'RouteCheck': ['Are X and Y connected by rail?',\n",
       "  'Is there a train connecting X and Y?']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb8b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_similiarity = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0176adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_similiarity(sentence,question):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    sent = nlp(sentence)\n",
    "    q = nlp(question)\n",
    "    return sent.similarity(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523b7112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TrainCheck': 0.5426949245536091, 'RouteCheck': 0.702159006316426}\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    intent_similiarity[i] = np.mean(list(map(question_similiarity,data[i],[qs]*len(data[i]))))\n",
    "print(intent_similiarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8338078",
   "metadata": {},
   "source": [
    "# Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24e565",
   "metadata": {},
   "source": [
    "## Preparing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c5e8f",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63c9a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = pd.read_csv(\"..\\data\\All_Indian_Trains.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5930645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Train no.</th>\n",
       "      <th>Train name</th>\n",
       "      <th>Starts</th>\n",
       "      <th>Ends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12723</td>\n",
       "      <td>Andhra Pradesh Express</td>\n",
       "      <td>Hyderabad Decan</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22416</td>\n",
       "      <td>Andhra Pradesh Express</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vishakapatnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12724</td>\n",
       "      <td>Andhra Pradesh Express</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Hyderabad Decan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12707</td>\n",
       "      <td>Andhra Pradesh Sampark Kranti</td>\n",
       "      <td>Tirupati</td>\n",
       "      <td>H Nizamuddin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15909</td>\n",
       "      <td>Abadh Assam Express</td>\n",
       "      <td>New Tinsukia Junction</td>\n",
       "      <td>Darbhanga Junction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Train no.                     Train name  \\\n",
       "0           0      12723         Andhra Pradesh Express   \n",
       "1           1      22416         Andhra Pradesh Express   \n",
       "2           2      12724         Andhra Pradesh Express   \n",
       "3           3      12707  Andhra Pradesh Sampark Kranti   \n",
       "4           4      15909            Abadh Assam Express   \n",
       "\n",
       "                  Starts                Ends  \n",
       "0        Hyderabad Decan           New Delhi  \n",
       "1              New Delhi       Vishakapatnam  \n",
       "2              New Delhi     Hyderabad Decan  \n",
       "3               Tirupati        H Nizamuddin  \n",
       "4  New Tinsukia Junction  Darbhanga Junction  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63a207e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = trains.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46d54150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train no.</th>\n",
       "      <th>Train name</th>\n",
       "      <th>Starts</th>\n",
       "      <th>Ends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12723</td>\n",
       "      <td>Andhra Pradesh Express</td>\n",
       "      <td>Hyderabad Decan</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22416</td>\n",
       "      <td>Andhra Pradesh Express</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Vishakapatnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12724</td>\n",
       "      <td>Andhra Pradesh Express</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Hyderabad Decan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12707</td>\n",
       "      <td>Andhra Pradesh Sampark Kranti</td>\n",
       "      <td>Tirupati</td>\n",
       "      <td>H Nizamuddin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15909</td>\n",
       "      <td>Abadh Assam Express</td>\n",
       "      <td>New Tinsukia Junction</td>\n",
       "      <td>Darbhanga Junction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train no.                     Train name                 Starts  \\\n",
       "0      12723         Andhra Pradesh Express        Hyderabad Decan   \n",
       "1      22416         Andhra Pradesh Express              New Delhi   \n",
       "2      12724         Andhra Pradesh Express              New Delhi   \n",
       "3      12707  Andhra Pradesh Sampark Kranti               Tirupati   \n",
       "4      15909            Abadh Assam Express  New Tinsukia Junction   \n",
       "\n",
       "                 Ends  \n",
       "0           New Delhi  \n",
       "1       Vishakapatnam  \n",
       "2     Hyderabad Decan  \n",
       "3        H Nizamuddin  \n",
       "4  Darbhanga Junction  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32a0f6",
   "metadata": {},
   "source": [
    "### Seggragating different forms of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64b2d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "num2name = data[\"TrainCheck\"][0]\n",
    "name2number = data[\"TrainCheck\"][1]\n",
    "route_check = data[\"RouteCheck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3b4ad",
   "metadata": {},
   "source": [
    "### All the available unique entities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "02ba309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_nos = list(set(trains[\"Train no.\"]))\n",
    "all_train_names = list(set(trains[\"Train name\"]))\n",
    "all_stations = list(set(list(trains[\"Starts\"])+list(trains[\"Ends\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325aa2d",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f23266b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c35e565",
   "metadata": {},
   "source": [
    "#### Randomly sampling 20 entries of train numbers and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "05432cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nos_sampled = random.sample(all_train_nos,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c76bfec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names_sampled = random.sample(all_train_names,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c495f",
   "metadata": {},
   "source": [
    "#### Creating training data for TrainCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "19967b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(zip(train_nos_sampled,train_names_sampled)):\n",
    "    prepared_str = num2name.replace(\"X\",str(i[0])).replace(\"Y\",i[1])\n",
    "    training_data.append((prepared_str,{\"entities\":[getFirstMatch(str(i[0]),prepared_str,\"CARDINAL\"),getFirstMatch(i[1],prepared_str,\"FAC\")]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "436127a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(zip(train_nos_sampled,train_names_sampled)):\n",
    "    prepared_str = name2number.replace(\"Y\",str(i[0])).replace(\"X\",i[1])\n",
    "    training_data.append((prepared_str,{\"entities\":[getFirstMatch(str(i[0]),prepared_str,\"CARDINAL\"),getFirstMatch(i[1],prepared_str,\"FAC\")]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddef04",
   "metadata": {},
   "source": [
    "#### Creating training data for RouteCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7b2e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for qs in route_check:\n",
    "        station1 = random.choice(all_stations)\n",
    "        station2 = random.choice(all_stations)\n",
    "        prepared_str = qs.replace(\"X\",station1).replace(\"Y\",station2)\n",
    "        training_data.append((prepared_str,{\"entities\":[getFirstMatch(station1,prepared_str,\"GPE\"),getFirstMatch(station2,prepared_str,\"GPE\")]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b44ea",
   "metadata": {},
   "source": [
    "#### Storing the generated training data in a json document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12f22d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'..\\data\\ner_training_data.json', 'w') as f:\n",
    "    json.dump({\"training_data\":training_data}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3fc39",
   "metadata": {},
   "source": [
    "## Fine tuning the NER pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf64437",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a89558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in training_data:\n",
    "  for ent in annotations.get(\"entities\"):\n",
    "    ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c498a",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c3c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
