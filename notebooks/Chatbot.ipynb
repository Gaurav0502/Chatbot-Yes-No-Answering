{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af292ff",
   "metadata": {},
   "source": [
    "# Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9878844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import spacy\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "feb4a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "     -------------------------------------- 79.7/79.7 kB 221.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.19.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.6.5)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mitug\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.5.18.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120735 sha256=f61beb28f0900e4ed36e348db670a579326c3b2907b52ff1135e3209ac251875Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Stored in directory: c:\\users\\mitug\\appdata\\local\\pip\\cache\\wheels\\2b\\11\\3b\\32a18fb9f2253b25d3d1a06f0a84e2d516e7efa19c8c71a283\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: torchvision, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.0 torchvision-0.12.0\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa4912",
   "metadata": {},
   "source": [
    "# Question Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6dd1b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 56788 the train number of R Express?\n"
     ]
    }
   ],
   "source": [
    "qs = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50719300",
   "metadata": {},
   "source": [
    "# Intent Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1599f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"..\\data\\intent_classification_data.json\")\n",
    "data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f536698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainCheck': ['Is X the train number of Y?', 'Does X have train number Y?'],\n",
       " 'RouteCheck': ['Are X and Y connected by rail?',\n",
       "  'Is there a train connecting X and Y?']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e99d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_similiarity = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0bfff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_similiarity(sentence,question):\n",
    "    sent = nlp(sentence)\n",
    "    q = nlp(question)\n",
    "    return sent.similarity(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48fd23aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TrainCheck': 0.7433274625513855, 'RouteCheck': 0.5845521191261642}\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    intent_similiarity[i] = np.mean(list(map(question_similiarity,data[i],[qs]*len(data[i]))))\n",
    "print(intent_similiarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63caf75",
   "metadata": {},
   "source": [
    "# Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c37a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8618193633531551\n",
      "0.6248355617496157\n",
      "0.5708127814142552\n",
      "0.5982914568380734\n",
      "0.5883917835046543\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# it works with single words too\n",
    "sent = nlp('Does X have train number Y?')\n",
    "sent1 = nlp('Is X the train number of Y?')\n",
    "sent2 = nlp('Is 56788 the train number of R Express?')\n",
    "sent3 = nlp('Does Andhra Pradesh Express have train number 12723?')\n",
    "sent4 = nlp('Are X and Y connected by rail?')\n",
    "sent5 = nlp('Is there a train connecting X and Y?')\n",
    "\n",
    "# similarity ranges from 0 (totally dissimilar) to 1 (identical)\n",
    "\n",
    "print(sent1.similarity(sent2))\n",
    "print(sent.similarity(sent2))\n",
    "print(sent4.similarity(sent2))\n",
    "print(sent5.similarity(sent2))\n",
    "print(sent1.similarity(sent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab326bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4918]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentences = [\"Is X the train number of Y?\", \"Is 12723 the train number of Andhra Pradesh Express?\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embedding_1= model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "## tensor([[0.6003]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63d6f0",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cea07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[0.4986]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
